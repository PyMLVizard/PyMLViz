{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../widgets/config_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set() # set default plot styles\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes and functions from the previous parts\n",
    "from jupyter_cms.loader import load_notebook\n",
    "smpl_index = load_notebook('./Sampling_Index.ipynb')\n",
    "smpl_index.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyStan\n",
    "\n",
    "*Stan* is a probabilistic programming language which uses automatic differentiation and Hamiltonian MC under the hood. Its default sampler is called **NUTS** (No U-Turn Sampler) which has no free parameters. It is based on the idea that a good proposal should efficiently explore the distribution and thus, move as far away from the starting point as possible. NUTS integrates the Hamiltonian until the direction of motion starts to point back to the starting point, i.e. it would make a U-turn.\n",
    "\n",
    "Note: The actual algorithm is more complicated as it needs to ensure that the proposal is reversible and obeys detailed balance.\n",
    "\n",
    "Below is the linear regression model in PyStan $\\ldots$ it would be very similar when using RStan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-dimensional Gaussian example\n",
    "model_gauss = \"\"\"\n",
    "    data {\n",
    "    }\n",
    "    transformed data {\n",
    "        matrix[2,2] Sigma;\n",
    "        vector[2] mu;\n",
    "        \n",
    "        mu[1] <- 0; mu[2] <- 0;\n",
    "        Sigma[1,1] <- 1; Sigma[1,2] <- 0.99; Sigma[2,1] <- 0.99; Sigma[2,2] <- 1;\n",
    "    }\n",
    "    parameters {\n",
    "        vector[2] x;\n",
    "    }\n",
    "    model {\n",
    "        x ~ multi_normal(mu, Sigma);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models are compiled for MyBinder, if it is not working \n",
    "# just uncomment the next line and compile the model for your system.\n",
    "\n",
    "#stan_gauss = pystan.StanModel(model_code=model_gauss, model_name='gauss_2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for the further use\n",
    "#with open('stan_models/gauss_2D.pkl', 'wb') as f:\n",
    "#    pickle.dump(stan_gauss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "stan_gauss = pickle.load(open('stan_models/gauss_2D.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model (draw samples)\n",
    "fit_gauss = stan_gauss.sampling(iter=100, chains=4, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling and sampling in pystan in one line\n",
    "#fit_gauss = pystan.stan(model_code=model_gauss, iter=42, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = fit_gauss.extract('x')['x']\n",
    "plt.plot(x[:,0], x[:,1], 'r-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian linear regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_blr = \"\"\"\n",
    "    data {\n",
    "        int<lower=1> N; // Number of samples\n",
    "        int<lower=1> D; // Number of features\n",
    "        matrix[N,D] X; // Design matrix\n",
    "        vector[N] t; // target values\n",
    "    }\n",
    "    parameters {\n",
    "        vector[D] w; // weight vector\n",
    "        real<lower=0> sigma; // Observation noise\n",
    "    }\n",
    "    model {\n",
    "        vector[N] y;\n",
    "        \n",
    "        w ~ normal(0, 100); // Prior p(w)\n",
    "        y <- X*w;\n",
    "        t ~ normal(y, sigma);\n",
    "    }\n",
    "    generated quantities {\n",
    "        real<lower=0> mse; // Training error\n",
    "        real R2; // Explained variance\n",
    "        vector[N] y;\n",
    "        \n",
    "        y <- X*w;\n",
    "        mse <- 1.0/N*dot_self(y-t);\n",
    "        R2 <- 1.0 - mse/variance(t);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models are compiled for MyBinder, if it is not working \n",
    "# just uncomment the next line and compile the model for your system.\n",
    "\n",
    "#stan_blr = pystan.StanModel(model_code=model_blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for the future use\n",
    "#with open('stan_models/blr.pkl', 'wb') as f:\n",
    "#    pickle.dump(stan_blr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "stan_blr = pickle.load(open('stan_models/blr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce example data\n",
    "N = 250\n",
    "x = np.hstack([np.ones((N,1)), 5+np.random.normal(size=(N,1))])\n",
    "t = np.dot(x, np.array([-1,2])) + np.random.normal(size=(N,), scale=0.8)\n",
    "plt.plot(x[:,1], t, 'k.')\n",
    "\n",
    "# Fit the model\n",
    "fit_blr = stan_blr.sampling(data={'N': N, 'D': x.shape[1], 'X': x, 't': t}, \\\n",
    "                       iter=1000, chains=4, seed=42)\n",
    "\n",
    "\n",
    "fit_blr.plot(['w','sigma', 'R2']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2D = pd.DataFrame(fit_blr.extract('w')['w'], columns=['r$w_0$', 'r$w_1$'])\n",
    "\n",
    "xlim, ylim = zip(df_2D.min(0), df_2D.max(0))\n",
    "with sns.axes_style('ticks'):\n",
    "    jointplot = sns.jointplot('r$w_0$', 'r$w_1$',\n",
    "                              xlim=xlim, ylim=ylim,\n",
    "                              data=df_2D, kind=\"hex\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Both, Gibbs sampling and HMC utilize informed proposal distributions to achieve efficient sampling. Yet, we have seen that Gibbs sampling mixes slowly when there are strong dependencies in the posterior. HMC can fail to explore the posterior in this case as well, albeit for a very different reason. Here the numerical integration of the Hamiltonian dynamics can lead to divergent trajectories if the local curvature of the posterior is large. Luckily, we can often diagnose this problem as Stan informs us about divergent trajectories.\n",
    "\n",
    "The following table compares Gibbs sampling and HMC\n",
    "<table>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>Gibbs sampling</th>\n",
    "<th>HMC</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Informed proposal</td>\n",
    "<td>Conditional distribution</td>\n",
    "<td>Gradient of log density</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Discrete distributions</td>\n",
    "<td>Yes</td>\n",
    "<td>No</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Continuous densities</td>\n",
    "<td>Requires conjugacy</td>\n",
    "<td>Yes</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Invariance</td>\n",
    "<td>Scaling</td>\n",
    "<td>Rotation</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Sampling problems</td>\n",
    "<td>High dependencies</td>\n",
    "<td>Curved geometry</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we investigate Neal's funnel, a standard example which poses problems for HMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neal_funnel (x, y):\n",
    "    return np.exp(norm(0, 3).logpdf(y) + np.sum(norm(0, np.exp(y/2.)).logpdf(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.linspace(-3,3,75), np.linspace(-10,3,75))\n",
    "plt.contour(X, Y, np.vectorize(lambda x, y: neal_funnel(x, y))(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution has a very thin (low volume) \"funnel\" which nevertheless holds about half of the probability density. A good sampler now needs to explore a large volume of low density as well as moving into the thin funnel.\n",
    "\n",
    "* Will the Gibbs sampler be able to explore Neal's funnel?\n",
    "* Note: Neither globally rescaling or rotating the distribution will reduce this difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_funnel = \"\"\"\n",
    "data {\n",
    "  int<lower=0> D;\n",
    "}\n",
    "parameters {\n",
    "  real x[D];\n",
    "  real y;\n",
    "}\n",
    "model {\n",
    "  y ~ normal(0, 3);\n",
    "  x ~ normal(0, exp(y/2));\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models are compiled for MyBinder, if it is not working \n",
    "# just uncomment the next line and compile the model for your system.\n",
    "\n",
    "#stan_funnel = pystan.StanModel(model_code=model_funnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for the further use\n",
    "#with open('stan_models/funnel.pkl', 'wb') as f:\n",
    "#    pickle.dump(stan_funnel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "stan_funnel = pickle.load(open('stan_models/funnel.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce example data\n",
    "D = 10\n",
    "fit_funnel = stan_funnel.sampling(data={'D': D}, seed=42)\n",
    "\n",
    "s = fit_funnel.extract(permuted=False)\n",
    "d = np.concatenate([x['divergent__'] for x in fit_funnel.get_sampler_params(inc_warmup=False)])\n",
    "print (np.sum(d), 'divergent trajectories') \n",
    "plt.scatter(s[:,:,0].T.flatten()[d==0], s[:,:,D].T.flatten()[d==0], color='b')\n",
    "plt.scatter(s[:,:,0].T.flatten()[d==1], s[:,:,D].T.flatten()[d==1], color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Stan has difficulties to move into the funnel and there are several divergent trajectories. Also the traceplot does not look quite right as y seems to get stuck occasionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_funnel.traceplot()\n",
    "plt.figure()\n",
    "plt.plot(fit_funnel.extract(permuted=False)[:,:,D]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is numerical problem of the integration we can try to use a smaller stepsize. This will take more time but the trajectory will be more accurate. The NUTS sampler that Stan uses by default does not allow to set the stepsize directly, but will adjust it during warmup. By increasing the control parameter *adapt_delta* we can nevertheless enforce smaller stepsizes.\n",
    "\n",
    "As expected the exploration of the sampler improves with adapt_delta=0.99 (default is 0.8). Now there are fewer (no) divergent trajectories and the sampler moves deeper into the funnel. Yet the traceplot for *y* is still problematic ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_funnel_99 = stan_funnel.sampling(data={'D': D}, control={'adapt_delta': 0.99}, seed=42)\n",
    "\n",
    "s = fit_funnel_99.extract(permuted=False)\n",
    "d = np.concatenate([x['divergent__'] for x in fit_funnel_99.get_sampler_params(inc_warmup=False)])\n",
    "print (np.sum(d), 'divergent trajectories') \n",
    "plt.scatter(s[:,:,0].T.flatten()[d==0], s[:,:,D].T.flatten()[d==0], color='b')\n",
    "plt.scatter(s[:,:,0].T.flatten()[d==1], s[:,:,D].T.flatten()[d==1], color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fit_funnel.extract()['y'], alpha=0.5, bins=100, normed=True, color='b')\n",
    "plt.hist(fit_funnel_99.extract()['y'], alpha=0.5, bins=100, normed=True, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_funnel_99.extract(permuted=False)[:,:,D]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this problem we need to reduce the dependency in the posterior. The so called *non centered* parametrization achives this by introducing a latent variable which has a standard normal prior. The original parameter is now computed from this latent variable which is now truly independent from the log standard deviation $y$ of $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_funnel_non_centered = \"\"\"\n",
    "data {\n",
    "  int<lower=1> D;\n",
    "}\n",
    "parameters {\n",
    "  real x_raw[D];\n",
    "  real y_raw;\n",
    "}\n",
    "transformed parameters {\n",
    "  real x[D];\n",
    "  real y;\n",
    "\n",
    "  y <- 3 * y_raw;\n",
    "  for (d in 1:D)\n",
    "    x[d] <- exp(y/2) * x_raw[d];\n",
    "}\n",
    "model {\n",
    "  y_raw ~ normal(0, 1);\n",
    "  x_raw ~ normal(0, 1);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models are compiled for MyBinder, if it is not working \n",
    "# just uncomment the next line and compile the model for your system.\n",
    "\n",
    "#stan_funnel_non_centered = pystan.StanModel(model_code=model_funnel_non_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for the further use\n",
    "#with open('stan_models/funnel_non_centered.pkl', 'wb') as f:\n",
    "#    pickle.dump(stan_funnel_non_centered, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the compiled model\n",
    "stan_funnel_non_centered = pickle.load(open('stan_models/funnel_non_centered.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "fit_funnel_non_centered = stan_funnel_non_centered.sampling(data={'D': D}, seed=42)\n",
    "\n",
    "s = fit_funnel_non_centered.extract()\n",
    "d = np.concatenate([x['divergent__'] for x in fit_funnel_non_centered.get_sampler_params(inc_warmup=False)])\n",
    "print (np.sum(d), 'divergent trajectories') \n",
    "plt.scatter(s['x'][:,0], s['y'], color='b')\n",
    "\n",
    "plt.figure()\n",
    "s = fit_funnel_non_centered.extract()\n",
    "plt.scatter(s['x_raw'][:,0], s['y']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_funnel_non_centered.plot()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fit_funnel_non_centered.extract(permuted=False)[:,:,D]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non centered parametrization the sampler quickly mixes and explores the full funnel. An even better solution -- which does not require to change the model -- is Riemannian HMC which correctly accounts for the geometry (local metric) of the space and can thereby integrate the Hamiltonian without problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fit_funnel.extract()['y'], alpha=0.5, bins=100, normed=True, color='b')\n",
    "plt.hist(fit_funnel_99.extract()['y'], alpha=0.5, bins=100, normed=True, color='r')\n",
    "plt.hist(fit_funnel_non_centered.extract()['y'], alpha=0.5, bins=100, normed=True, color='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "2fd5586857324f34aab1de2033092afd",
   "lastKernelId": "67b50a78-b358-41a0-9f9e-25be5f7093c2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
